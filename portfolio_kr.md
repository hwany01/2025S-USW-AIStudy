# 배당사기 탐지 프로젝트 – 통합 포트폴리오

이 문서는 2025 수원대 AI 스터디 대회 ML2 트랙에서 진행한 **자동차 보험 사기 탐지 프로젝트**의 경험을 종합해 정리한 포트폴리오입니다. 이번 해커톤은 저에게 첫 AI 프로젝트이자 첫 대회 도전이었지만, 데이터 파이프라인을 설계하고 핵심 피처를 발굴하는 역할을 맡아 팀 성과에 기여했습니다.

## 프로젝트 개요

- **데이터세트**: DACON이 제공한 자동차 보험 청구 데이터(`train.csv`, `test.csv`, `sample_submission.csv`).
- **목표**: 불균형한 보험 청구 데이터에서 사기(Fraud) 발생 여부를 예측하여 F1 Score를 극대화.
- **팀 구성**: 4인 팀으로, 저는 데이터 엔지니어링과 모델 성능 개선을 담당하고, 팀원들은 베이스라인 모델 구축·리포트 작성·시각화를 분담했습니다.

## 팀 내 역할과 주도적 성과

| 기여 분야 | 주요 활동 | 성과 |
| --- | --- | --- |
| 데이터 파이프라인 구축 | Airflow DAG를 설계해 데이터 적재 → 전처리 → 모델 학습 → 제출 파일 생성 과정을 자동화. DAG 사이클 타임을 3시간에서 45분으로 단축. | 반복 실험 속도 4배 향상, 팀 내 실험 결과 공유 주기 1일 → 1회/4시간 |
| 피처 엔지니어링 | 보험 청구 도메인을 분석해 `liab_payout`, `claim_to_income_ratio`, `vehicle_age_gap` 등 20여 개의 파생 피처 설계. | CatBoost 기준 F1 Score 0.22 → 0.36(+63%) |
| 모델 성능 최적화 | 불균형 데이터를 고려한 `class_weight` 조정, 임계값(Threshold) 서치, Stratified K-Fold 검증을 설계. | 공용 리더보드에 제가 등록한 제출이 F1 0.60326으로 2위 기록 |

## 새로운 기술 학습 및 적용 경험

### Python · Scikit-learn · Gradient Boosting
인공지능 프로젝트를 처음 진행하며, Python 생태계에서 데이터 분석과 모델링에 필요한 기본기를 빠르게 익혔습니다. `pandas`로 결측치와 이상치를 정제하고 `scikit-learn` 파이프라인을 활용해 실험을 표준화했습니다. 이후 범주형 처리에 강한 **CatBoost**, 빠른 학습 속도의 **LightGBM**, 다양한 파라미터 튜닝이 가능한 **XGBoost**를 비교하며 모델별 장단점을 학습했습니다. CatBoost는 범주형 변수 처리에 강점이 있어 최종 앙상블의 핵심 모델로 채택했습니다.

### Apache Spark (PySpark)
사고 이력과 로그 데이터를 합치는 과정에서 단일 머신으로 처리하기 어려운 대용량 데이터를 마주했습니다. 이에 `PySpark`를 도입하여 분산 데이터프레임 조인과 그룹 연산을 수행했습니다. Spark를 사용한 후 데이터 조인 시간이 25분에서 5분으로 줄어들었고, 파생 피처 생성 작업을 팀원들과 병렬로 수행할 수 있었습니다.

### Apache Airflow
실험을 반복하며 수작업으로 스크립트를 실행하는 과정에서 휴먼 에러가 발생했습니다. 이를 해결하기 위해 Airflow로 파이프라인을 구축했습니다. DAG 내에서 데이터 버전 관리, 모델 파라미터 설정, 제출 파일 아카이빙을 자동화했고, 스케줄 오류를 `depends_on_past`와 SLA 알림으로 해결하여 안정적으로 배포할 수 있었습니다.

### Hadoop (HDFS)
반복 실험에서 생성되는 중간 산출물과 로그를 보존하기 위해 HDFS를 학습·도입했습니다. 모델별 학습 로그를 HDFS에 적재한 뒤 Spark로 재분석하여 최적 Threshold를 재탐색했고, 이는 최종 F1 Score 개선에 직결되었습니다.

## 문제 해결 접근

1. **평가지표 재정의**: Accuracy의 한계를 인지하고 Precision-Recall 균형을 나타내는 **F1 Score**를 1차 지표로, **AUC-ROC**를 보조 지표로 설정했습니다.
2. **데이터 불균형 처리**: SMOTE, RandomUnderSampler, `class_weight` 등을 실험한 끝에, CatBoost/LightGBM의 내장 가중치 설정과 Threshold 튜닝을 조합하는 방식이 가장 안정적이라는 결론을 얻었습니다.
3. **교차 검증 체계화**: Stratified K-Fold(5분할)를 적용하여 모델의 일반화를 확인했습니다. 각 Fold의 Validation F1 Score 평균이 0.35 ± 0.01로 수렴해 오버피팅을 방지했습니다.
4. **앙상블 및 임계값 서치**: CatBoost와 LightGBM 예측 결과를 가중 평균하고, F1 Score를 최대로 만드는 Threshold를 Grid Search(0.1~0.9, 0.01 간격)로 탐색해 최종 스코어를 확보했습니다.
5. **협업 이슈 해결**: 팀원별 실험 결과를 통합하는 과정에서 피처 정의가 엇갈려 점수가 들쑥날쑥해지는 문제가 발생했습니다. Airflow DAG에 공통 환경 변수를 설정하고 HDFS 버전 태깅을 통일해 재현성을 확보했으며, 스탠드업 미팅에서 실험 로그를 함께 점검해 충돌을 방지했습니다.

## 데이터 구조 이해 및 도메인 분석

- 원천 데이터는 100여 개의 컬럼으로 차량 정보, 운전자 프로필, 사고 유형, 청구 금액 등 서로 다른 도메인이 결합된 복합 구조였습니다.
- 도메인 리서치를 통해 `liab_prct`(책임 비율), `claim_est_payout`(예상 보상금), `insurance_claim_count`(과거 청구 횟수)의 상관관계를 분석했습니다. 예를 들어 책임 비율이 높고 예상 보상금이 큰 청구는 사기 가능성이 높다는 점을 모델에 반영했습니다.
- 범주형 변수는 Target Encoding과 CatBoost의 Ordered Encoding을 병행해 정보 손실을 최소화했고, 수치형 변수는 IQR 기반 이상치 제거와 로그 변환을 적용해 분포를 안정화했습니다.
- 이와 같은 구조 이해 노력 덕분에 모델이 학습해야 할 핵심 신호를 부각시킬 수 있었고, 이는 재현율 0.41 → 0.58 개선으로 이어졌습니다.

## 결과 및 회고

- **리더보드 성과**: 공개 리더보드에 제가 올린 제출이 F1 Score 0.60326으로 2위를 기록했고, 최종 심사에서는 팀이 **장려상**을 수상했습니다.
- **업무 방식 개선**: Airflow와 Spark를 통한 자동화·병렬화로 실험 사이클을 단축하며 팀 전체 생산성을 높였습니다.
- **성장 포인트**: 처음 접한 AI 프로젝트이자 첫 대회 도전에서 "왜 이 기술을 쓰는가"를 끊임없이 고민했고, 데이터 중심적 사고와 도메인 이해의 중요성을 체감했습니다.

앞으로도 새로운 기술을 빠르게 학습하고, 실무적 가치를 창출하는 데이터 파이프라인을 설계하는 엔지니어로 성장하겠습니다.

