# [2025 데이스쿨 ML2] 자동차 보험 사기 탐지 – 인터뷰 노트

> 해커톤 경험을 되돌아보며, 새로운 기술 학습·팀 내 역할·데이터 구조 이해에 초점을 맞춰 정리한 인터뷰 준비 노트입니다.  
> 인공지능 프로젝트와 데이터 대회 도전이 모두 처음이었지만, **팀장으로서 전체 파이프라인을 설계하고 실험 프로세스를 주도하며** 팀의 F1 Score를 크게 향상시켰습니다.

---

## 1. 새로운 기술을 학습하고 적용한 경험

### 왜 Python과 Gradient Boosting을 선택했나요?
- 해커톤 기간이 짧아 빠른 실험이 필요했습니다. Python의 `pandas`, `NumPy`, `scikit-learn`은 풍부한 튜토리얼과 커뮤니티 덕분에 빠르게 습득할 수 있었고, 데이터 정제부터 모델 평가까지 일관된 워크플로우를 제공했습니다.
- 범주형 변수가 많은 보험 데이터 특성상, 범주 처리가 수월한 **CatBoost**와 학습 속도가 빠른 **LightGBM**을 비교 실험했습니다. CatBoost는 별도의 One-Hot Encoding 없이도 좋은 성능을 보여 최종 앙상블의 중심 모델로 채택했습니다.

### Spark와 Hadoop을 도입한 이유는 무엇인가요?
- 로그성 보조 데이터와 본 데이터를 조인할 때 단일 머신으로는 20분 이상이 소요되었습니다. PySpark 기반 분산 처리로 동일 작업을 5분 내에 끝내며, 한정된 해커톤 시간 동안 더 많은 실험을 진행할 수 있었습니다.
- 반복 실험에서 나오는 모델 로그·피처 중요도 파일을 장기 보관하기 위해 `Hadoop HDFS`를 사용했습니다. HDFS에 저장된 로그를 다시 Spark로 분석해 임계값을 조정했고, 그 결과 재현율이 0.41에서 0.58로 상승했습니다.

### Airflow를 통해 무엇을 해결했나요?
- 수동으로 실행하던 스크립트 순서를 여러 번 실수하면서 실험 추적이 어려웠습니다.  
  **팀장 백승환으로서**, 실험 전 과정을 자동화하고 팀원 간 작업 환경을 통일하기 위해 Airflow DAG를 직접 설계했습니다.  
- `데이터 적재 → 전처리 → 모델 학습 → 제출 파일 생성` 과정을 자동화하면서,  
  DAG 사이클이 3시간에서 45분으로 단축되어 실험 속도가 약 4배 빨라졌고, 팀원 모두가 동일 환경에서 재현 가능한 실험을 수행할 수 있었습니다.

---

## 2. 팀에서 맡은 역할과 달라진 결과

| 맡은 역할 | 구체적인 실행 | 변화/성과 |
| --- | --- | --- |
| **팀장 / 데이터 파이프라인 리더** | 전체 실험 구조 설계, Airflow DAG 구성, PySpark 전처리 스크립트 작성, HDFS 로그 관리 | 반복 실험 자동화 → 오류 재실행 시간 30분 → 5분 |
| 피처 엔지니어 | 보험 도메인 리서치를 기반으로 `claim_to_income_ratio`, `vehicle_age_gap`, `liab_payout` 등 파생 피처 20여 개 설계 | CatBoost Validation F1 Score 0.22 → 0.36 (+63%) |
| 모델 평가 책임 | Stratified K-Fold, Threshold Grid Search, Class Weight 튜닝 | 대회 당시 공개 리더보드 F1 0.58대 기록 · 최종 장려상 수상 |

### 협업 중 직면한 문제와 해결
- 팀원별로 생성한 파생 피처 정의가 엇갈리면서 모델 성능이 실험마다 불안정해지는 문제가 있었습니다.  
- **팀장으로서**, Airflow DAG에 공통 파라미터를 적용하고 HDFS 버전 태깅을 통일해 재현성을 확보했습니다.  
- 매일 스탠드업에서 실험 로그를 함께 점검하며 충돌을 예방했고, 실험 이력과 버전 관리를 중앙 집중화했습니다.  
- 이러한 구조적 개선으로 팀 전체가 동일한 기준과 코드를 공유하며 더 빠르게 실험을 반복할 수 있었습니다.

---

## 3. 데이터 구조를 깊이 이해하려 한 과정

1. **복합 데이터 맥락 파악**: 차량 정보, 운전자 이력, 청구 상세 등 100여 개 컬럼이 얽혀 있었습니다. 도메인 문헌을 찾아 사고 책임 비율(`liab_prct`)과 예상 보상금(`claim_est_payout`)이 결합될 때 사기 가능성이 커진다는 점을 확인했습니다.  
2. **데이터 품질 개선**: IQR 기반 이상치 제거, 로그 변환으로 분포를 안정화했고, 범주형 변수에는 Target Encoding과 CatBoost Ordered Encoding을 병행해 정보 손실을 최소화했습니다.  
3. **성능 검증**: 파생 피처의 중요도를 SHAP 값으로 확인하며 모델 해석 가능성을 확보했습니다. 이 과정을 통해 실제 사기 청구를 더 많이 포착할 수 있었고, 최종 재현율이 0.58까지 향상되었습니다.  

---

## 4. 배운 점과 향후 계획

- 처음 도전한 AI 프로젝트이자 첫 대회였기에 기술 선택의 이유와 기대 효과를 명확히 정의하는 것이 무엇보다 중요했습니다.  
- 데이터 중심적 사고와 자동화된 실험 관리가 짧은 기간 동안 높은 성과를 내는 핵심임을 체감했습니다.  
- **팀장 백승환으로서**, 협업 구조를 설계하고 프로세스로 문제를 해결한 경험을 통해 **재현성과 효율성을 갖춘 리더십**을 배우게 되었습니다.  
- 대회 종료 후에도 아쉬움이 남아, 직접 코드를 다시 정비하며 추가 실험을 진행했습니다.  
  대회는 장려상으로 마무리되었지만, 끝난 뒤에도 아쉬움이 남아 혼자 이것저것 실험을 이어갔습니다.  
  결국 그 과정에서 모델 성능을 더 끌어올려 **공개 리더보드 기준 2위**까지 올리며 프로젝트의 잠재력을 확인했습니다.  
- 이후의 실험 결과와 개선 과정은 모두 개인 GitHub 저장소에 기록하며, 기술적 성장의 기반으로 삼았습니다.  

> 대회는 장려상으로 마무리되었지만, 이후 **팀장 백승환**이 개인적으로 여러 시도를 이어가며 모델 구조를 재정비했고, 결과적으로 공개 리더보드 2위까지 도달하며 프로젝트의 잠재력과 리더십을 입증했습니다.
