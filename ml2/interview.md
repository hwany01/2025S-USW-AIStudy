# [2025 데이스쿨 ML2] 자동차 보험 사기 탐지 – 인터뷰 노트

> 해커톤 경험을 되돌아보며, 새로운 기술 학습·팀 내 역할·데이터 구조 이해에 초점을 맞춰 정리한 인터뷰 준비 노트입니다. 인공지능 프로젝트와 데이터 대회 도전이 모두 처음이었지만, 데이터 파이프라인 구축과 피처 엔지니어링을 주도하며 팀의 F1 Score를 크게 끌어올렸습니다.

## 1. 새로운 기술을 학습하고 적용한 경험

### 왜 Python과 Gradient Boosting을 선택했나요?
- 해커톤 기간이 짧아 빠른 실험이 필요했습니다. Python의 `pandas`, `NumPy`, `scikit-learn`은 풍부한 튜토리얼과 커뮤니티 덕분에 빠르게 습득할 수 있었고, 데이터 정제부터 모델 평가까지 일관된 워크플로우를 제공했습니다.
- 범주형 변수가 많은 보험 데이터 특성상, 범주 처리가 수월한 **CatBoost**와 학습 속도가 빠른 **LightGBM**을 비교 실험했습니다. CatBoost는 별도의 One-Hot Encoding 없이도 좋은 성능을 보여 최종 앙상블의 중심 모델로 채택했습니다.

### Spark와 Hadoop을 도입한 이유는 무엇인가요?
- 로그성 보조 데이터와 본 데이터를 조인할 때 단일 머신으로는 20분 이상이 소요되었습니다. `PySpark`의 분산 처리로 동일 작업을 5분 내에 끝낼 수 있어, 한정된 해커톤 시간 동안 더 많은 실험을 진행할 수 있었습니다.
- 반복 실험에서 나오는 모델 로그·피처 중요도 파일을 장기 보관하기 위해 `Hadoop HDFS`를 사용했습니다. HDFS에 저장된 로그를 다시 Spark로 분석해 임계값을 조정했고, 그 결과 재현율이 0.41에서 0.58로 상승했습니다.

### Airflow를 통해 무엇을 해결했나요?
- 수동으로 실행하던 스크립트 순서를 여러 번 실수하면서 실험 추적이 어려웠습니다. Airflow DAG를 만들어 `데이터 적재 → 전처리 → 모델 학습 → 제출 파일 생성`을 자동화했습니다.
- DAG 사이클이 3시간에서 45분으로 줄어 실험 속도가 약 4배 빨라졌고, 팀원들에게 항상 최신 결과를 공유할 수 있었습니다.

## 2. 팀에서 맡은 역할과 달라진 결과

| 맡은 역할 | 구체적인 실행 | 변화/성과 |
| --- | --- | --- |
| 데이터 파이프라인 리더 | Airflow DAG 설계, PySpark 전처리 스크립트 작성, HDFS 로그 관리 | 반복 실험 자동화 → 오류 재실행 시간 30분 → 5분 |
| 피처 엔지니어 | 보험 도메인 리서치를 기반으로 `claim_to_income_ratio`, `vehicle_age_gap`, `liab_payout` 등 파생 피처 20여 개 설계 | CatBoost Validation F1 Score 0.22 → 0.36 (+63%) |
| 모델 평가 책임 | Stratified K-Fold, Threshold Grid Search, Class Weight 튜닝 | 공개 리더보드에 제가 올린 제출 F1 0.60326 (2위 기록) · 최종 장려상 |

### 협업 중 직면한 문제와 해결
- 팀원별로 생성한 파생 피처 정의가 엇갈리면서 모델 성능이 실험마다 불안정해지는 문제가 있었습니다.
- Airflow DAG에 공통 파라미터를 적용하고 HDFS 버전 태깅을 통일해 재현성을 확보했으며, 매일 스탠드업에서 실험 로그를 함께 점검하며 충돌을 예방했습니다.

## 3. 데이터 구조를 깊이 이해하려 한 과정

1. **복합 데이터 맥락 파악**: 차량 정보, 운전자 이력, 청구 상세 등 100여 개 컬럼이 얽혀 있었습니다. 도메인 문헌을 찾아 사고 책임 비율(`liab_prct`)과 예상 보상금(`claim_est_payout`)이 결합될 때 사기 가능성이 커진다는 점을 확인했습니다.
2. **데이터 품질 개선**: IQR 기반 이상치 제거, 로그 변환으로 분포를 안정화했고, 범주형 변수에는 Target Encoding과 CatBoost Ordered Encoding을 병행해 정보 손실을 최소화했습니다.
3. **성능 검증**: 파생 피처의 중요도를 SHAP 값으로 확인하며 모델 해석 가능성을 확보했습니다. 이 과정을 통해 실제 사기 청구를 더 많이 포착할 수 있었고, 최종 재현율이 0.58까지 향상되었습니다.

## 4. 배운 점과 향후 계획

- 처음 도전한 AI 프로젝트이자 첫 대회였기에 기술 선택의 이유와 기대 효과를 명확히 정의하는 것이 무엇보다 중요했습니다.
- 데이터 중심적 사고와 자동화된 실험 관리가 짧은 기간 동안 높은 성과를 내는 핵심임을 체감했습니다.
- 팀원들과의 협업에서 발생한 피처 정의 불일치를 프로세스로 해결한 경험을 통해, 재현성 있는 실험 관리의 중요성을 배웠습니다.
- 앞으로도 새로운 기술을 빠르게 학습해 실무적 가치를 창출하는 데이터 엔지니어로 성장하고자 합니다.

> 최종적으로 공개 리더보드에서는 제가 업로드한 제출이 2위를 기록했고, 팀은 협업 성과를 인정받아 장려상을 수상했습니다.

